# -*- coding: utf-8 -*-
"""success

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1HuDdN__wtLsGr25QzIXXXM9heuqzhHKv
"""

def detect_and_decode_barcode(image):
    barcodes = decode(image)
    for barcode in barcodes:
        barcode_data = barcode.data.decode("utf-8")
        barcode_type = barcode.type

        print("Barcode Data:", barcode_data)
        print("Barcode Type:", barcode_type)

        return True
    return False

!pip install groq

!pip install easyocr

!pip install torch torchvision torchaudio opencv-python

!pip install pyzbar

!pip install ultralytics

!pip install -r https://raw.githubusercontent.com/ultralytics/yolov5/master/requirements.txt
!git clone https://github.com/ultralytics/yolov11.git
!cd yolov5
!pip install -r requirements.txt
!sudo apt-get install -y libgl1

!sudo apt-get install libzbar0

import os
from groq import Groq

import easyocr
import spacy
from collections import Counter
import re
from pyzbar.pyzbar import decode
# nlp=spacy.load("en_core_web_sm")


# Set up your API key as an environment variable
os.environ["GROQ_API_KEY"] = "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"

# Initialize the Groq client
client = Groq(api_key=os.environ.get("GROQ_API_KEY"))

def generate_reply(current_prompt):
    # Create a chat completion with a robust system message for OCR data
    chat_completion = client.chat.completions.create(
        messages=[
            {
                "role": "system",
                "content": (
                    '''Extract and refine the following details from the text provided. The text may contain inaccuracies due to OCR extraction. Utilize your own knowledge and contextual understanding to correct and fill in any missing information as needed:
                    give output in format like {
                      product name:,
                      ... other details
                    }
                    dont give long explanations

1. **Product Name**: Identify and provide the correct name of the product, ensuring it is accurately represented.

2. **Manufacturing Details**: Extract and clarify the company name, manufacturing date, location, and any relevant manufacturing license numbers. If this information is ambiguous or incomplete, use your knowledge to infer or correct it.

3. **Manufacturing Date**: Determine the manufacturing date of the product. If no specific date is provided, extract any text that resembles a date and offer the most likely interpretation.

4. **Expiry Date**: Identify the expiry date of the product. This information may not be explicitly mentioned, so extract any text that resembles a date and interpret it in the context of expiration.

5. **Packaging Details**: Extract detailed packaging information including net weight, serving size, price per pack, and any other relevant packaging information. Use your knowledge to correct or clarify any ambiguous details.

6. **Contact Information**: Identify and provide contact numbers, email addresses, and physical addresses for consumer queries. If there are discrepancies or missing information, use contextual clues to provide the most accurate information possible.

7. show other details also which you can get or predict if information is available.If information is nbot given dont say that it is not given hust dont show it.

Please ensure that the extracted details are coherent and contextually accurate, leveraging your understanding of product information.
'''
                )
            },
            {
                "role": "user",
                "content": current_prompt
            }

        ],
        model="llama-3.1-70b-versatile",
    )

    # Return the generated reply
    return chat_completion.choices[0].message.content




read=easyocr.Reader(['en'])
print('------------------------------------------------------------------------------------------------------------------------------------------------------')



import torch
import cv2
import os
from collections import Counter
import matplotlib.pyplot as plt

# Load the YOLOv5 model
model = torch.hub.load('ultralytics/yolov5', 'yolov5s', pretrained=True)

# Load an image
img_path = 'xyz.jpg'  # Replace with your image path
img = cv2.imread(img_path)  # Load the image using OpenCV

# Perform inference
results = model(img_path)

# Print results
results.print()  # Print results to console

# Get bounding boxes and labels
boxes = results.xyxy[0]  # Get detections as a tensor
labels = results.names  # Get label names

# Create a directory for cropped images
output_dir = 'cropped_images'
os.makedirs(output_dir, exist_ok=True)

# List to hold detected class names
detected_classes = []
print('------------------------------------------------------------------------------------------------------------------------------------------------------')


# Loop through each detection
# Move the boxes tensor to CPU before converting to NumPy
for i, (x1, y1, x2, y2, conf, cls) in enumerate(boxes.cpu().numpy()): # This line is changed
    # Extract the bounding box coordinates
    bbox = (int(x1), int(y1), int(x2), int(y2))

    # Crop the image using the bounding box
    cropped_img = img[bbox[1]:bbox[3], bbox[0]:bbox[2]]

    # Get the class name
    class_name = labels[int(cls)]
    detected_classes.append(class_name)

    image=cropped_img

    cropped_image_path = os.path.join(output_dir, f'cropped_{i}_{class_name}.png')
    cv2.imwrite(cropped_image_path, cropped_img)

    read_text=read.readtext(image,detail=0)

    detect_and_decode_barcode(image)
    para=" ".join(read_text)
    print('------------------------------------------------------------------------------------------------------------------------------------------------------')

    print(generate_reply(para))

    print('------------------------------------------------------------------------------------------------------------------------------------------------------')


# Count occurrences of each class
counts = Counter(detected_classes)

# Display the counts
print("\033[34mProduct" + " " * 15 + "Count\033[0m")
for item, count in counts.items():
    print(f"{item:<20} = {count}")

import torch
import cv2
import os
from collections import Counter
import matplotlib.pyplot as plt

# Load the YOLOv5 model
model = torch.hub.load('ultralytics/yolov5', 'yolov5s', pretrained=True)

# Load an image
img_path = 'xyzz.jpg'  # Replace with your image path
img = cv2.imread(img_path)  # Load the image using OpenCV

# Perform inference
results = model(img_path)

# Print results
results.print()  # Print results to console

# Get bounding boxes and labels
boxes = results.xyxy[0]  # Get detections as a tensor
labels = results.names  # Get label names

# Create a directory for cropped images
output_dir = 'cropped_images'
os.makedirs(output_dir, exist_ok=True)

# List to hold detected class names
detected_classes = []
print('------------------------------------------------------------------------------------------------------------------------------------------------------')


# Loop through each detection
# Move the boxes tensor to CPU before converting to NumPy
for i, (x1, y1, x2, y2, conf, cls) in enumerate(boxes.cpu().numpy()): # This line is changed
    # Extract the bounding box coordinates
    bbox = (int(x1), int(y1), int(x2), int(y2))

    # Crop the image using the bounding box
    cropped_img = img[bbox[1]:bbox[3], bbox[0]:bbox[2]]

    # Get the class name
    class_name = labels[int(cls)]
    detected_classes.append(class_name)

    image=cropped_img

    cropped_image_path = os.path.join(output_dir, f'cropped_{i}_{class_name}.png')
    cv2.imwrite(cropped_image_path, cropped_img)

    read_text=read.readtext(image,detail=0)
    if detect_and_decode_barcode(image)!=False:
      print(detect_and_decode_barcode(image))
    para=" ".join(read_text)
    print('------------------------------------------------------------------------------------------------------------------------------------------------------')

    print(generate_reply(para))

    print('------------------------------------------------------------------------------------------------------------------------------------------------------')


# Count occurrences of each class
counts = Counter(detected_classes)

# Display the counts
print("\033[34mProduct" + " " * 15 + "Count\033[0m")
for item, count in counts.items():
    print(f"{item:<20} = {count}")

import torch
import cv2
import os
from collections import Counter
import matplotlib.pyplot as plt

# Load the YOLOv5 model
model = torch.hub.load('ultralytics/yolov5', 'yolov5s', pretrained=True)

# Load an image
img_path = 'xyzz.jpg'  # Replace with your image path
img = cv2.imread(img_path)  # Load the image using OpenCV

# Perform inference
results = model(img_path)

# Print results
results.print()  # Print results to console

# Get bounding boxes and labels
boxes = results.xyxy[0]  # Get detections as a tensor
labels = results.names  # Get label names

# Create a directory for cropped images
output_dir = 'cropped_images'
os.makedirs(output_dir, exist_ok=True)

# List to hold detected class names
detected_classes = []
print('------------------------------------------------------------------------------------------------------------------------------------------------------')


# Loop through each detection
# Move the boxes tensor to CPU before converting to NumPy
for i, (x1, y1, x2, y2, conf, cls) in enumerate(boxes.cpu().numpy()): # This line is changed
    # Extract the bounding box coordinates
    bbox = (int(x1), int(y1), int(x2), int(y2))

    # Crop the image using the bounding box
    cropped_img = img[bbox[1]:bbox[3], bbox[0]:bbox[2]]

    # Get the class name
    class_name = labels[int(cls)]
    detected_classes.append(class_name)

    image=cropped_img

    cropped_image_path = os.path.join(output_dir, f'cropped_{i}_{class_name}.png')
    cv2.imwrite(cropped_image_path, cropped_img)

    read_text=read.readtext(image,detail=0)
    if detect_and_decode_barcode(image)!=False:
      print(detect_and_decode_barcode(image))
    para=" ".join(read_text)
    print('------------------------------------------------------------------------------------------------------------------------------------------------------')

    print(generate_reply(para))

    print('------------------------------------------------------------------------------------------------------------------------------------------------------')


# Count occurrences of each class
counts = Counter(detected_classes)

# Display the counts
print("\033[34mProduct" + " " * 15 + "Count\033[0m")
for item, count in counts.items():
    print(f"{item:<20} = {count}")

# Load an image
img_path = 'yyy.jpg'  # Replace with your image path
img = cv2.imread(img_path)  # Load the image using OpenCV

read_text=read.readtext(img,detail=0)

if detect_and_decode_barcode(image)!=False:
      print(detect_and_decode_barcode(image))

para=" ".join(read_text)

print(generate_reply(para))

import torch
import cv2
import os
from collections import Counter
import matplotlib.pyplot as plt

# Load the YOLOv5 model
model = torch.hub.load('ultralytics/yolov5', 'yolov5s', pretrained=True)

# Load an image
img_path = 'xyzz.jpg'  # Replace with your image path
img = cv2.imread(img_path)  # Load the image using OpenCV

# Perform inference
results = model(img_path)

# Print results
results.print()  # Print results to console

# Get bounding boxes and labels
boxes = results.xyxy[0]  # Get detections as a tensor
labels = results.names  # Get label names

# Create a directory for cropped images
output_dir = 'cropped_images'
os.makedirs(output_dir, exist_ok=True)

# List to hold detected class names
detected_classes = []
print('------------------------------------------------------------------------------------------------------------------------------------------------------')


# Loop through each detection
# Move the boxes tensor to CPU before converting to NumPy
for i, (x1, y1, x2, y2, conf, cls) in enumerate(boxes.cpu().numpy()): # This line is changed
    # Extract the bounding box coordinates
    bbox = (int(x1), int(y1), int(x2), int(y2))

    # Crop the image using the bounding box
    cropped_img = img[bbox[1]:bbox[3], bbox[0]:bbox[2]]

    # Get the class name
    class_name = labels[int(cls)]
    detected_classes.append(class_name)

    image=cropped_img

    cropped_image_path = os.path.join(output_dir, f'cropped_{i}_{class_name}.png')
    cv2.imwrite(cropped_image_path, cropped_img)

    read_text=read.readtext(image,detail=0)
    if detect_and_decode_barcode(image)!=False:
      print(detect_and_decode_barcode(image))
    para=" ".join(read_text)
    print('------------------------------------------------------------------------------------------------------------------------------------------------------')

    print(generate_reply(para))

    print('------------------------------------------------------------------------------------------------------------------------------------------------------')


# Count occurrences of each class
counts = Counter(detected_classes)

# Display the counts
print("\033[34mProduct" + " " * 15 + "Count\033[0m")
for item, count in counts.items():
    print(f"{item:<20} = {count}")

